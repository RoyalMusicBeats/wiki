{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#about-me","title":"About me","text":"<p>Hello there! I'm a 22-year-old IT enthusiast, always eager to embark on a journey into the ever-evolving world of technology. My name is Rick, and I find my true passion in the intricate workings of IT systems.</p> <p>My love for technology knows no bounds, and I proudly traverse the diverse landscapes of both Windows and Linux operating systems. I revel in the beauty of their nuances and embrace the challenges they bring, constantly expanding my knowledge and skills.</p> <p>Diving into the realm of containers and orchestration, I have honed my expertise in Docker and Kubernetes. These tools, for me, are like the conductors of a symphony, harmonizing the deployment and scaling of applications with precision and finesse.</p> <p>Virtualization, too, is a realm I've embraced. There's something mesmerizing about transcending hardware limitations, witnessing the magic of virtual machines and their impact on modern IT landscapes.</p> <p>At 22, I'm just getting started on my IT journey, and I couldn't be more excited about the possibilities that lie ahead. Learning is my constant companion, and I'm always on the lookout for the next technological challenge to conquer.</p> <p>In the ever-changing world of IT, I find my purpose and my playground. From optimizing systems to unraveling complex problems, I'm ready to make my mark and explore the uncharted territories of technology. Join me as I navigate this exciting digital landscape, one line of code at a time.</p>"},{"location":"#projects","title":"Projects","text":"<ul> <li>K3s with Tailscale: This project involves setting up and configuring a Kubernetes cluster using K3s, a lightweight Kubernetes distribution, and integrating it with Tailscale, a secure networking tool. This combination enables secure and easy-to-manage communication between nodes in your cluster.</li> <li> <p>Link:</p> </li> <li> <p>K3s with Longhorn: In this project, you're likely implementing Longhorn, a cloud-native distributed block storage system, within your K3s Kubernetes cluster. Longhorn can help manage persistent storage for your containerized applications, ensuring data resilience and reliability.</p> </li> <li>Link:</li> </ul> <p>These projects demonstrate your engagement with Kubernetes, containerization, and networking technologies, showcasing your dedication to enhancing infrastructure and application management. Good luck with your endeavors!</p>"},{"location":"Linux/Docker/1.%20Setup%20Arr%27s/","title":"1. Setup Arr's","text":""},{"location":"Linux/Docker/1.%20Setup%20Arr%27s/#introduction","title":"Introduction","text":"<pre><code>version: \"3.8\"\nservices:\n\n  radarr:\n    image: lscr.io/linuxserver/radarr:latest\n    container_name: radarr\n    environment:\n      - PUID=1000\n      - PGID=1000\n      - TZ=Europe/Amsterdam\n    volumes:\n      - /path_to_config:/config # (1)!\n      - /path_to_data:/movies # (2)!\n      - /path_to_downloads:/downloads # (3)!\n    ports:\n      - 7878:7878\n    restart: always\n\n  sonarr:\n    image: lscr.io/linuxserver/sonarr:latest\n    container_name: sonarr\n    environment:\n      - PUID=1000\n      - PGID=1000\n      - TZ=Europe/Amsterdam\n    volumes:\n      - /mnt/docker/sonarr:/config\n      - /mnt/serie:/tv\n      - /mnt/download:/downloads\n    ports:\n      - 8989:8989\n    restart: always\n</code></pre> <ol> <li> <p>Change the <code>/path_to_config</code> secsion to your dessired config location.</p> </li> <li> <p>Change the <code>/path_to_data</code> secsion to your dessired data location.</p> </li> <li> <p>Change the <code>/path_to_downloads</code> secsion to your dessired downloads location.</p> </li> </ol> <pre><code>theme:\n  features:\n    - content.code.annotate # (1)!\n</code></pre> <ol> <li> I'm a code annotation! I can contain <code>code</code>, formatted     text, images, ... basically anything that can be written in Markdown.</li> </ol>"},{"location":"Linux/IaC/Requirements/","title":"Requirements","text":""},{"location":"Linux/IaC/Requirements/#introduction","title":"Introduction","text":"<p>nano /usr/share/perl5/PVE/APIServer/AnyEvent.pm search for \"timeout\" change 30 to 300</p>"},{"location":"Linux/K3s/1.%20Setup%20K3s%20with%20Tailscale/","title":"1. Setup K3s with Tailscale","text":""},{"location":"Linux/K3s/1.%20Setup%20K3s%20with%20Tailscale/#introduction","title":"Introduction","text":"<p>In this guide, we will be exploring how to set up K3s, a lightweight Kubernetes distribution, with Tailscale, a VPN that provides secure network connectivity between machines on the Internet. K3s is designed to be a lightweight and easy-to-install Kubernetes distribution that is ideal for use in resource-constrained environments, such as small edge devices, IoTdevices, and low-powered ARM-based devices. Tailscale provides a secure way to connect these devices to each other and to the Internet, without the need for complex networking configurations. By combining K3s with Tailscale, we can create a simple, secure, and scalable Kubernetes cluster that is easy to set up and manage.</p>"},{"location":"Linux/K3s/1.%20Setup%20K3s%20with%20Tailscale/#installing-and-configuring-tailscale","title":"Installing and configuring Tailscale","text":"<p>Install the Tailscale client by running the following command: <pre><code>curl -fsSL https://tailscale.com/install.sh | sh\n</code></pre> After installing Tailscale, you can authenticate your device by running the following command: <pre><code>sudo tailscale up\n</code></pre> After joining the Tailscale network, you can verify that your device is connected by running the following command: <pre><code>tailscale status\n</code></pre> This needs to be done on every worker en master node.</p>"},{"location":"Linux/K3s/1.%20Setup%20K3s%20with%20Tailscale/#setup-the-first-k3s-master-node","title":"Setup the first K3s master node","text":"<p>To register our K3s master node, we can use the following command: <pre><code>curl -sfL https://get.k3s.io | K3S_TOKEN=YOUR-TOKEN sh -s - server --cluster-init --flannel-iface tailscale0\n</code></pre></p> Here's a breakdown of the various components of this command: <ul> <li>curl: This is a command-line utility for transferring data from or to a server, using various protocols. In this case, it is used to download the script from the given URL.</li> <li>-sfL: These are options to the curl command. -s tells curl to operate silently, without showing progress or error messages. -f tells curl to fail silently if the HTTP response code indicates an error. -L tells curl to follow redirects if the server sends them.</li> <li>https://get.k3s.io: This is the URL from which the script is downloaded.</li> <li>|: This is a pipe symbol that connects the output of the curl command to the input of the next command, which is sh.</li> <li>K3S_TOKEN=\"YOUR-TOKEN\": This sets an environment variable called K3S_TOKEN to the value YOUR-TOKEN. The environment variable will be available to the script that is run by sh.</li> <li>sh: This is the command that runs the script that was downloaded by curl. The script is executed by the shell program sh.</li> <li>-s: This option tells the shell program sh to read commands from standard input (i.e., the pipe from curl) instead of from a script file.</li> <li>-server --cluster-init --flannel-iface tailscale0: These are arguments that are passed to the script that is executed by sh. The script is a script to install the K3s Kubernetes distribution, and these arguments configure the installation. --cluster-init configures K3s to set up a new Kubernetes cluster. --flannel-iface tailscale0 configures the Flannel networkinterface to use tailscale0.</li> </ul>"},{"location":"Linux/K3s/1.%20Setup%20K3s%20with%20Tailscale/#retrieving-the-full-token-from-our-k3s-master-server","title":"Retrieving the full-token from our k3s master server","text":"<p>To retrieve the token from a K3s server, we can use the following command: <pre><code>cat /var/lib/rancher/k3s/server/token\n</code></pre> This will display the token value that was generated during the installation of the K3s server. </p> <p>Danger</p> <p>The token is used to authenticate new nodes that are added to the Kubernetes cluster. Be sure to keep the token value secure, as it provides full access to the Kubernetes API server.</p>"},{"location":"Linux/K3s/1.%20Setup%20K3s%20with%20Tailscale/#adding-another-k3s-master-server","title":"Adding another K3s master server","text":"<p>On the new master server, run the following command to join the cluster: <pre><code>curl -sfL https://get.k3s.io | K3S_TOKEN=YOUR-FULL-TOKEN sh -s - server --server https://YOUR-TAILSCALE-IP:6443  --flannel-iface tailscale0\n</code></pre></p> Here's a breakdown of the various components of this command: <ul> <li>K3S_TOKEN=\"YOUR-FULL-TOKEN\": This sets the token value for the K3s server installation. Replace \"YOUR-TOKEN\" with the token value generated by the K3s master node.</li> <li>sh -s - server: This executes the downloaded K3s installation script with the server parameter, indicating that this is a K3s server node.</li> <li>--server https://YOUR-TAILSCALE-IP:6443: This specifies the IP address of the K3s server node that is being installed. Replace \"YOUR-TAILSCALE-IP\" with the IP address of the first master server.</li> <li>--flannel-iface tailscale0: This specifies the Tailscale virtual network interface to use for communication between the K3s nodes.</li> </ul> <p>By following these steps, you should now have a multi-master K3s cluster with two master servers. You can repeat these steps to add additional master servers to the cluster if desired.</p>"},{"location":"Linux/K3s/1.%20Setup%20K3s%20with%20Tailscale/#adding-a-k3s-agent-node","title":"Adding a K3s agent node","text":"<pre><code>curl -sfL https://get.k3s.io | K3S_TOKEN=YOUR-FULL-TOKEN K3S_URL=https://YOUR-TAILSCALE-IP:6443 sh -s - --flannel-iface tailscale0\n</code></pre>"},{"location":"Linux/K3s/1.%20Setup%20K3s%20with%20Tailscale/#optional-installing-longhorn","title":"Optional: Installing longhorn","text":"<p>Installing longhorn on K3s</p>"},{"location":"Linux/K3s/1.%20Setup%20K3s%20with%20Tailscale/#trouble","title":"Trouble","text":"<p><pre><code>kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml\n</code></pre> <pre><code>https://longhorn.io/kb/troubleshooting-dns-resolution-failed/\n</code></pre></p>"},{"location":"Linux/K3s/2.%20Setup%20K3s%20with%20Longhorn/","title":"2. Setup K3s with Longhorn","text":""},{"location":"Linux/K3s/2.%20Setup%20K3s%20with%20Longhorn/#introduction","title":"Introduction","text":""},{"location":"Linux/K3s/3.%20Setup%20K3s%20with%20Tdarr/","title":"3. Setup K3s with Tdarr","text":""},{"location":"Linux/K3s/3.%20Setup%20K3s%20with%20Tdarr/#introduction","title":"Introduction","text":""},{"location":"Linux/Linux/1.%20Setup%20Nvidia%20GPU%20in%20Ubuntu/","title":"1. Setup Nvidia GPU in Ubuntu","text":""},{"location":"Linux/Linux/1.%20Setup%20Nvidia%20GPU%20in%20Ubuntu/#introduction","title":"Introduction","text":"<p>sudo ubuntu-drivers autoinstall</p> <p>nvidia-smi</p>"},{"location":"Linux/OPNsense/1.%20Change%20network%20interfaces%20names/","title":"1. Change network interfaces names","text":""},{"location":"Linux/OPNsense/1.%20Change%20network%20interfaces%20names/#introduction","title":"Introduction","text":"<p>This guide explains how to change the names of network interfaces on OPNsense.</p>"},{"location":"Linux/OPNsense/1.%20Change%20network%20interfaces%20names/#steps","title":"Steps","text":"<ol> <li> <p>Navigate to the directory <code>/usr/local/etc/rc.syshook.d/early</code>.</p> </li> <li> <p>Copy any file in this directory and clear its contents.</p> </li> <li> <p>Add the following script to the file:</p> <pre><code>#!/bin/sh\n\nifconfig em0 name net0\nifconfig em1 name net1\nifconfig em2 name net2\n</code></pre> <p>Danger</p> <p>This script is an example. You need to replace <code>em0</code>, <code>em1</code>, and <code>em2</code> with the actual names of your network interfaces and <code>net0</code>, <code>net1</code>, and <code>net2</code> with the desired new names.</p> </li> </ol> <p>This script renames the network interfaces <code>em0</code>, <code>em1</code>, and <code>em2</code> to <code>net0</code>, <code>net1</code>, and <code>net2</code> respectively.</p>"},{"location":"Linux/Proxmox/1.%20proxmox%20gpu/","title":"1. proxmox gpu","text":""},{"location":"Linux/Proxmox/1.%20proxmox%20gpu/#introduction","title":"Introduction","text":""},{"location":"Linux/Proxmox/1.%20proxmox%20gpu/#check-iommu-support","title":"Check IOMMU Support","text":"<p>Open a terminal. Run the following command to check for IOMMU support in your system: <pre><code>dmesg | grep -e IOMMU\n</code></pre> This command will display information about IOMMU support. If you see relevant information, it means IOMMU is supported on your hardware.</p>"},{"location":"Linux/Proxmox/1.%20proxmox%20gpu/#edit-grub-configuration","title":"Edit GRUB Configuration","text":"<p>To enable IOMMU in the GRUB bootloader, you need to edit the /etc/default/grub file. You can use a text editor like nano or vi to do this. For example:</p> <p><pre><code>sudo nano /etc/default/grub\n</code></pre> Find the line that starts with GRUB_CMDLINE_LINUX_DEFAULT. It may look something like this:</p> <p><pre><code>GRUB_CMDLINE_LINUX_DEFAULT=\"quiet splash\"\n</code></pre> Modify the line to include IOMMU settings. Add intel_iommu=on iommu=pt to the existing settings within the double quotes. It should look like this:</p> <p><pre><code>GRUB_CMDLINE_LINUX_DEFAULT=\"quiet intel_iommu=on iommu=pt\"\n</code></pre> Save the file and exit the text editor.</p>"},{"location":"Linux/Proxmox/1.%20proxmox%20gpu/#update-grub","title":"Update GRUB","text":"<p>After modifying the GRUB configuration, you need to update GRUB to apply the changes. Run the following command: <pre><code>sudo update-grub\n</code></pre> This command regenerates the GRUB configuration with the updated settings.</p>"},{"location":"Linux/Proxmox/1.%20proxmox%20gpu/#verify-iommu-settings","title":"Verify IOMMU Settings","text":"<p>To verify that the IOMMU settings have been correctly applied, you can once again run the following command: <pre><code>dmesg | grep -e IOMMU\n</code></pre> This will display any IOMMU-related information in your system logs. If the settings were applied correctly, you should see relevant output indicating that IOMMU is enabled.</p>"},{"location":"Linux/Proxmox/Tips%20%26%20Tricks/Delete/Resize%20lvm-data%20volume/","title":"Resize lvm data volume","text":""},{"location":"Linux/Proxmox/Tips%20%26%20Tricks/Delete/Resize%20lvm-data%20volume/#remove-and-resize-the-default-lvm-data-volume","title":"Remove and resize the default lvm-data volume","text":"<pre><code>lvremove /dev/pve/data\n</code></pre>"},{"location":"Linux/Proxmox/Tips%20%26%20Tricks/Delete/Resize%20lvm-data%20volume/#resize-root-partition","title":"Resize root partition","text":"<pre><code>lvresize -l +100%FREE /dev/pve/root\n</code></pre>"},{"location":"Linux/Proxmox/Tips%20%26%20Tricks/Delete/Resize%20lvm-data%20volume/#completing","title":"Completing","text":"<pre><code>resize2fs /dev/mapper/pve-root\n</code></pre>"},{"location":"Linux/Proxmox/Tips%20%26%20Tricks/Delete/Resize%20lvm-data%20volume/#verification","title":"Verification","text":"<pre><code>lsblk\n</code></pre>"},{"location":"Windows/Windows%20Deployment%20Services/1.Setting%20Up%20a%20Windows%20Deployment%20Services%20%28WDS%29%20Server/","title":"Setting Up a Windows Deployment Services (WDS) Server","text":"<p>Windows Deployment Services (WDS) is a Microsoft server technology used for network-based installation of Windows operating systems. This guide will walk you through the steps to set up a WDS server.</p>"},{"location":"Windows/Windows%20Deployment%20Services/1.Setting%20Up%20a%20Windows%20Deployment%20Services%20%28WDS%29%20Server/#prerequisites","title":"Prerequisites","text":"<p>Before setting up WDS, ensure the following: - A Windows Server machine with the WDS role installed. - Active Directory, DHCP, and DNS configured in your environment. - A Windows installation image (e.g., <code>.wim</code> file).</p>"},{"location":"Windows/Windows%20Deployment%20Services/1.Setting%20Up%20a%20Windows%20Deployment%20Services%20%28WDS%29%20Server/#steps-to-set-up-wds","title":"Steps to Set Up WDS","text":""},{"location":"Windows/Windows%20Deployment%20Services/1.Setting%20Up%20a%20Windows%20Deployment%20Services%20%28WDS%29%20Server/#1-install-the-wds-role","title":"1. Install the WDS Role","text":"<ol> <li>Open Server Manager.</li> <li>Click on Add roles and features.</li> <li>Select Windows Deployment Services under the Server Roles section.</li> <li>Complete the wizard and restart the server if prompted.</li> </ol>"},{"location":"Windows/Windows%20Deployment%20Services/1.Setting%20Up%20a%20Windows%20Deployment%20Services%20%28WDS%29%20Server/#2-configure-wds","title":"2. Configure WDS","text":"<ol> <li>Open the Windows Deployment Services console.</li> <li>Right-click on the server name and select Configure Server.</li> <li>Follow the wizard:<ul> <li>Choose Integrated with Active Directory.</li> <li>Specify the location for the Remote Installation Folder.</li> <li>Configure PXE Server settings (e.g., respond to all client computers).</li> </ul> </li> </ol>"},{"location":"Windows/Windows%20Deployment%20Services/1.Setting%20Up%20a%20Windows%20Deployment%20Services%20%28WDS%29%20Server/#3-add-boot-and-install-images","title":"3. Add Boot and Install Images","text":"<ol> <li>In the WDS console, expand the server node.</li> <li>Right-click Boot Images and select Add Boot Image.<ul> <li>Browse to the <code>boot.wim</code> file from your Windows installation media.</li> </ul> </li> <li>Repeat the process for Install Images using the <code>install.wim</code> file.</li> </ol>"},{"location":"Windows/Windows%20Deployment%20Services/1.Setting%20Up%20a%20Windows%20Deployment%20Services%20%28WDS%29%20Server/#4-configure-dhcp-if-needed","title":"4. Configure DHCP (if needed)","text":"<p>If WDS and DHCP are on the same server: - Configure DHCP to include option 66 (PXE server name) and option 67 (boot file name).</p>"},{"location":"Windows/Windows%20Deployment%20Services/1.Setting%20Up%20a%20Windows%20Deployment%20Services%20%28WDS%29%20Server/#5-test-the-deployment","title":"5. Test the Deployment","text":"<ol> <li>Boot a client machine via PXE.</li> <li>Follow the on-screen instructions to install the operating system.</li> </ol>"},{"location":"Windows/Windows%20Deployment%20Services/1.Setting%20Up%20a%20Windows%20Deployment%20Services%20%28WDS%29%20Server/#additional-resources","title":"Additional Resources","text":"<ul> <li>Microsoft WDS Documentation</li> <li>Troubleshooting WDS</li> </ul> <p>By following these steps, you should have a fully functional WDS server ready for network-based OS deployments.</p>"},{"location":"Windows/Windows%20Deployment%20Services/2.test/","title":"Removing All Drivers from a .WIM File","text":"<p>This guide explains how to remove all drivers from a <code>.wim</code> file using <code>DISM</code> (Deployment Image Servicing and Management) tool.</p>"},{"location":"Windows/Windows%20Deployment%20Services/2.test/#prerequisites","title":"Prerequisites","text":"<ol> <li>A Windows machine with administrative privileges.</li> <li>The <code>.wim</code> file you want to modify.</li> <li>DISM tool (pre-installed on most Windows systems).</li> </ol>"},{"location":"Windows/Windows%20Deployment%20Services/2.test/#steps-to-remove-drivers","title":"Steps to Remove Drivers","text":"<ol> <li> <p>Mount the .WIM File     Mount the <code>.wim</code> file to a directory for modification:     <pre><code>dism /Mount-Wim /WimFile:\"C:\\path\\to\\your\\file.wim\" /Index:1 /MountDir:\"C:\\Mount\"\n</code></pre></p> </li> <li> <p>List Installed Drivers     View all drivers in the mounted <code>.wim</code> file:     <pre><code>dism /Image:\"C:\\Mount\" /Get-Drivers\n</code></pre></p> </li> <li> <p>Remove Drivers     Remove all third-party drivers from the image:     <pre><code>dism /Image:\"C:\\Mount\" /Remove-Driver /Driver:oem*.inf\n</code></pre></p> </li> <li> <p>Commit Changes     Save the changes and unmount the <code>.wim</code> file:     <pre><code>dism /Unmount-Wim /MountDir:\"C:\\Mount\" /Commit\n</code></pre></p> </li> <li> <p>Verify Changes     Optionally, remount the <code>.wim</code> file and list drivers again to confirm removal.</p> </li> </ol>"},{"location":"Windows/Windows%20Deployment%20Services/2.test/#notes","title":"Notes","text":"<ul> <li>Always back up your <code>.wim</code> file before making changes.</li> <li>Removing critical drivers may cause issues with deployment.</li> </ul>"},{"location":"Windows/Windows%20Deployment%20Services/2.test/#references","title":"References","text":"<ul> <li>Microsoft DISM Documentation</li> </ul>"}]}